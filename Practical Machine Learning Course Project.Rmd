---
title: "Practical Machine Learning Course Project"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# Load necessray libraries
```{r, results='hide'}
library(knitr)
library(caret)
library(rpart)
library(rpart.plot)
library(rattle)
library(randomForest)
library(corrplot)
set.seed(12345)
```

# Data Loading and Exploratory Analysis
## Data loading and cleaning
Load the dataset from URL. Then training dataset is partitioned in 2 to create a training set (70%) for modeling and a testing set (30%) for validations.
```{r}
UrlTrain = "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
UrlTest = "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"

training = read.csv(url(UrlTrain))
testing = read.csv(url(UrlTest))

inTrain = createDataPartition(training$classe, p=0.7, list=FALSE)
TrainSet = training[inTrain,]
TestSet = training[-inTrain,]
dim(TrainSet)
```

```{r}
dim(TestSet)
```

```{r}
# remove variables with nearly 0 variance
NZV = nearZeroVar(TrainSet)
TrainSet = TrainSet[, -NZV]
TestSet = TestSet[, -NZV]
dim(TrainSet)
```

```{r}
dim(TestSet)
```

```{r}
# remove variables that are mostly NA
AllNA = sapply(TrainSet, function(x) mean(is.na(x))) > 0.95
TrainSet = TrainSet[, AllNA==FALSE]
TestSet = TestSet[,AllNA==FALSE]
dim(TrainSet)
```

```{r}
dim(TestSet)
```

```{r}
# remove identification only variables
TrainSet = TrainSet[,-(1:5)]
TestSet = TestSet[,-(1:5)]
dim(TrainSet)
```

```{r}
dim(TestSet)
```

## Correlation Analysis
```{r}
par(mfrow=c(1,1))
corMatrix = cor(TrainSet[,-54])
corrplot(corMatrix, order = "FPC", method = "color", type = "lower", tl.cex = 0.8, tl.col = rgb(0,0,0))
```


The highly correlated variables are shown in dark colors in the graph above.

# Prediction Model Building
Three models, Random Forests, Decision Tree and Generalized Boosted mODEL, will be applied to model regression. 

## Random Forest
```{r}
set.seed(12345)
controlRF = trainControl(method="cv", number=3, verboseIter = FALSE)
modFitRandForest = train(classe~., data=TrainSet, method="rf", trControl=controlRF)
modFitRandForest$finalModel
```

```{r}
# prediction on the test dataset
predictRandForest = predict(modFitRandForest, newdata=TestSet)
confMatRandForest = confusionMatrix(predictRandForest, TestSet$classe)
confMatRandForest 
```

```{r}
# plot matrix results
plot(confMatRandForest$table, col = confMatRandForest$byClass, main = paste("Random Forest - Accuracy = ", round(confMatRandForest$overall["Accuracy"],4)))
```

## Method: Decision Trees
```{r}
# model
set.seed(12345)
modFitDecTree = rpart(classe ~., data=TrainSet, method = "class")
fancyRpartPlot(modFitDecTree)
```

```{r}
# predict on test dataset
predictDecTree = predict(modFitDecTree, newdata = TestSet, type="class")
confMatDecTree = confusionMatrix(predictDecTree,TestSet$classe)
confMatDecTree
```

```{r}
# plot matrix results
plot(confMatDecTree$table, col=confMatDecTree$byClass, main = paste("Decision Tree - Accuracy =", round(confMatDecTree$overall["Accuracy"],4)))
```

## Generalized Boosted Model
```{r}
# Model
set.seed(12345)
controlGBM = trainControl(method = "repeatedcv", number = 5, repeats=1)
modFitGBM = train(classe~., data=TrainSet, method="gbm",trControl = controlGBM, verbose = FALSE)
modFitGBM$finalModel
```

```{r}
# prediction on Test dataset
predictGBM= predict(modFitGBM, newdata = TestSet)
confMatGBM = confusionMatrix(predictGBM, TestSet$classe)
confMatGBM
```

```{r}
# plot matrix results
plot(confMatGBM$table, col = confMatGBM$byClass, main = paste("GBM - Accuracy = ", round(confMatGBM$overall["Accuracy"],4)))
```

# Apply the Selected Model to the Test Dataset
The accuracy of 3 models are: (1)Random Forest:0.9963; (2)Decision Tree:0.7368; (3)GBM:0.9839

Therefore, we select Random Forest model.

```{r}
predictTest = predict(modFitRandForest, newdata=testing)
predictTest
```





